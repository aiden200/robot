### **Day 8**

- **PAPER: Deep Q Learning**
  - Deep Q network
  - Experience replay
  - Critic Function
- **Paper Implementation: PPO pt 2**
  - Implemented Clipped Loss, KL divergence penalty coefficient
  - Finished the PPO Critic, Advantage score calculation
  - Started the main PPO Algo -> stuck in the Advantage calculation
  - Code located in [here](../code/models/ppo.py)
  - Things left: Environment configuration, loss updates, trajectory generation

### **Notes**

<div style="display: flex; justify-content: space-between;">
  <img src="../assets/day_8_paper_1.jpg" alt="Paper notes 1" width="45%">
  <img src="../assets/day_8_paper_2.jpg" alt="Paper notes 2" width="45%">
</div>
<br>
<div style="display: flex; justify-content: space-between;">
  <img src="../assets/day_8_paper_cover.jpg" alt="Paper Cover" width="45%">
</div>
